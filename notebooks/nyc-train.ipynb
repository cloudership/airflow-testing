{
 "cells": [
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "import aiobotocore\n",
    "import pandas as pd\n",
    "from dotenv import load_dotenv\n",
    "from numpy import dtype\n",
    "from s3fs import S3FileSystem\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.feature_extraction import DictVectorizer\n",
    "from sklearn.metrics import root_mean_squared_error\n",
    "from sklearn.model_selection import train_test_split\n"
   ],
   "id": "91083711af40b696",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "load_dotenv()\n",
    "[os.getenv(\"AWS_PROFILE\"), os.getenv(\"TRAINING_DIR\")]"
   ],
   "id": "a697813792494e62",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "tmpdir = Path.cwd().parent / \"tmp\"\n",
    "s3 = S3FileSystem(session=aiobotocore.session.AioSession(profile=os.getenv(\"AWS_PROFILE\")))\n",
    "bucket_root = f\"s3://{os.getenv(\"BUCKET_NAME\")}/ny_taxi_trip_prediction\"\n",
    "\n",
    "if os.getenv(\"TRAINING_DIR\"):\n",
    "    training_base_dir = os.getenv(\"TRAINING_DIR\")\n",
    "else:\n",
    "    training_base_dir = s3.read_text(f\"{bucket_root}/current\")\n",
    "\n",
    "training_root = f\"{bucket_root}/training/{training_base_dir}\"\n",
    "\n",
    "train_path = tmpdir / \"train.parquet\"\n",
    "if not train_path.is_file():\n",
    "    s3.get_file(training_root + \"/train.parquet\", train_path)\n",
    "df_train_val_all = pd.read_parquet(train_path)\n",
    "\n",
    "test_path = tmpdir / \"test.parquet\"\n",
    "if not test_path.is_file():\n",
    "    s3.get_file(training_root + \"/test.parquet\", test_path)\n",
    "df_test_all = pd.read_parquet(test_path)\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "assert df_train_val_all['PULocationID'].dtypes is dtype(\"int32\")\n",
    "assert df_test_all['PULocationID'].dtypes is dtype(\"int32\")"
   ],
   "id": "99fd80e7287a6b59",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "df_train_val_all.head()",
   "id": "4336270f1b75e82c",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "df_train_val_all[df_train_val_all.index.duplicated()]",
   "id": "71c6763bc1ff87b3",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# def preprocess(df: pd.DataFrame, dict_vec: DictVectorizer | None) -> [any, any, DictVectorizer]:\n",
    "#     \"\"\" Returns x, y, and dict vectorizer. If dict vectorizer was supplied in arguments, does not fit, only transforms.\n",
    "#     \"\"\"\n",
    "#     dict_vec_fit = False\n",
    "#     if dict_vec is None:\n",
    "#         dict_vec = DictVectorizer()\n",
    "#         dict_vec_fit = True\n",
    "#\n",
    "#     dfp = pd.DataFrame(index=df.index)\n",
    "#     dfp[\"duration_min\"] = (df[\"tpep_dropoff_datetime\"] - df[\"tpep_pickup_datetime\"]).apply(lambda timediff: timediff.total_seconds())\n",
    "#     dfp = dfp[(dfp.duration_min >= 1) & (dfp.duration_min <= 60)]\n",
    "#     dfp[\"loc_id\"] = df[\"PULocationID\"].astype(str) + \"-\" + df[\"DOLocationID\"].astype(str)\n",
    "#     dfp[\"trip_distance\"] = df[\"trip_distance\"]\n",
    "#\n",
    "#     dfp.reset_index(inplace=True, drop=True)\n",
    "#\n",
    "#     return dfp, dict_vec"
   ],
   "id": "2f9cec6bf177f2f1",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def preprocess(df: pd.DataFrame, dict_vec: DictVectorizer | None = None) -> [any, any, DictVectorizer]:\n",
    "    \"\"\" Returns x, y, and dict vectorizer. If dict vectorizer was supplied in arguments, does not fit, only transforms.\n",
    "    \"\"\"\n",
    "    dict_vec_fit = False\n",
    "    if dict_vec is None:\n",
    "        dict_vec = DictVectorizer()\n",
    "        dict_vec_fit = True\n",
    "\n",
    "    tmpdf = pd.DataFrame(index=df.index)\n",
    "    tmpdf[\"duration_min\"] = (df[\"tpep_dropoff_datetime\"] - df[\"tpep_pickup_datetime\"]).apply(\n",
    "        lambda timediff: timediff.total_seconds())\n",
    "    tmpdf = tmpdf[(tmpdf[\"duration_min\"] >= 1) & (tmpdf[\"duration_min\"] <= 60)]\n",
    "    tmpdf[\"loc_id\"] = df[\"PULocationID\"].astype(str) + \"-\" + df[\"DOLocationID\"].astype(str)\n",
    "    tmpdf[\"trip_distance\"] = df[\"trip_distance\"]\n",
    "    print(\"tmpdf\")\n",
    "    display(tmpdf)\n",
    "\n",
    "    x_dicts = tmpdf[[\"loc_id\", \"trip_distance\"]].to_dict(orient=\"records\")\n",
    "    print(\"x_dicts\")\n",
    "    display(x_dicts)\n",
    "    if dict_vec_fit:\n",
    "        x = dict_vec.fit_transform(x_dicts)\n",
    "    else:\n",
    "        x = dict_vec.transform(x_dicts)\n",
    "    print(\"x\")\n",
    "    display(x)\n",
    "    y = tmpdf[\"duration_min\"].values\n",
    "    print(\"y\")\n",
    "    display(y)\n",
    "\n",
    "    return x, y, dict_vec"
   ],
   "id": "b354d4b1ffa20703",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Take first 80% for training set, last 20% for validation set. Order DOES matter because we want to use later data for validation as it is in theory closer to reality\n",
    "xy_train_all, xy_val_all = train_test_split(df_train_val_all, test_size=0.2, shuffle=False)\n",
    "display(xy_train_all.head())\n",
    "display(xy_val_all.head())"
   ],
   "id": "8902fb91cf1defec",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "x_train, y_train, dv = preprocess(xy_train_all)",
   "id": "ffb064f6278faa8a",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "x_val, y_val, _ = preprocess(xy_val_all, dv)",
   "id": "b5f1db241331a5c5",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "x_test, y_test, _ = preprocess(df_test_all, dv)\n",
   "id": "ed5568e4d2b635e7",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-26T10:28:39.238580Z",
     "start_time": "2024-11-26T10:28:36.584018Z"
    }
   },
   "cell_type": "code",
   "source": [
    "model = RandomForestRegressor(max_depth=10, random_state=0)\n",
    "model.fit(x_train, y_train)\n",
    "y_pred_val = model.predict(x_val)\n",
    "y_pred_test = model.predict(x_test)\n",
    "\n",
    "print(f\"RMSE of validation set: {float(root_mean_squared_error(y_val, y_pred_val))}\")\n",
    "print(f\"RMSE of test set: {float(root_mean_squared_error(y_test, y_pred_test))}\")"
   ],
   "id": "8d25681448a465e1",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE of validation set: 13.783918857799998\n",
      "RMSE of test set: 13.382332322020392\n"
     ]
    }
   ],
   "execution_count": 39
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "print(\"Pick up location IDs\")\n",
    "display(xy_train_all[\"PULocationID\"].sort_values().unique())\n",
    "print(\"Drop off location IDs\")\n",
    "display(xy_train_all[\"DOLocationID\"].sort_values().unique())"
   ],
   "id": "b0ff5754fd833f73",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
